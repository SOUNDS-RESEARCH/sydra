import os
import random
import numpy as np

from joblib import Parallel, delayed
from omegaconf import DictConfig, OmegaConf

from pathlib import Path
from tqdm import tqdm


from .simulators.pyroomacoustics import pyroomacoustics_simulator
try:
    from .simulators.gpu_rir import gpu_rir_simulator
    IS_GPURIR_AVAILABLE = True
except ImportError as e:
    print(e)
    print("Could not import gpuRIR.")
    IS_GPURIR_AVAILABLE = False

from .hydra_utils import load_config
from .logger import save_dataset_metadata, save_signals
from .random.moving_source_config import generate_random_config_for_moving_source
from .random.static_source_config import generate_random_config_for_static_source
from .librispeech_dataset import LibriSpeechDataset


def from_dict(dataset_config, dataset_sample_configs=None):
    if isinstance(dataset_config, DictConfig):
        # Convert to dict
        dataset_config = OmegaConf.to_container(dataset_config)
    
    "Generate a dataset from a single config dict, such as one generated by hydra config"
    random.seed(dataset_config["random_seed"])
    np.random.seed(dataset_config["random_seed"])

    if dataset_config["sources"]["speech_signals_dir"]:
        _create_speech_config(dataset_config)

    output_dir = Path(dataset_config["dataset_dir"]) 
    _initialize_directory(output_dir / "samples")

    if dataset_config["acoustic_simulator"] == "gpuRIR":
        if not IS_GPURIR_AVAILABLE:
            print("""gpuRIR is not available.
                Please install it or set 'pyroomacoustcs'
                as your 'acoustic_simulator'""")
            return

    if dataset_sample_configs is None:
        dataset_sample_configs = Parallel(n_jobs=dataset_config["n_jobs"])(
            delayed(generate_sample)(dataset_config, f"samples/{num_sample}")
            for num_sample in tqdm(range(dataset_config["n_samples"]))
        )
    else:
        dataset_sample_configs = Parallel(n_jobs=dataset_config["n_jobs"])(
            delayed(generate_sample)(config, f"samples/{num_sample}", random=False)
            for num_sample, config in tqdm(enumerate(dataset_sample_configs))
        )

    print("Saving metadata...")
    save_dataset_metadata(dataset_sample_configs, output_dir,
                          dataset_config["metadata_format"])

    # Optional: Create a dataset with anechoic samples, used as target for dereverberation
    # This is being done using recursion, which can be seen as either elegant or hacky.
    if dataset_config["anechoic_dataset_dir"] is not None:
        print("Creating anechoic dataset...")

        dataset_config["dataset_dir"] = dataset_config["anechoic_dataset_dir"]
        dataset_config["anechoic_dataset_dir"] = None

        for config in dataset_sample_configs:
            config["anechoic"] = True
            config["dataset_dir"] = dataset_config["dataset_dir"] 
        
        from_dict(dataset_config, dataset_sample_configs)


def generate_sample(base_config=None, output_dir=None, random=True):
    if base_config is None:
        base_config = load_config()



    # 1. If provided config contain ranges, generate random coordinates, room dims, etc.
    config = base_config
    if random:
        # Ideally, the random config generator should be independent from the acoustic
        # engine, so these two should be merged into one, as much of the functionality is shared.
        if config["sources"]["moving"]:
            # if config["sources"]["n_sources"] != 1:
            #     print("Only one moving source is currently supported")
            
            config = generate_random_config_for_moving_source(base_config)
        else:
            config = generate_random_config_for_static_source(base_config)
            if base_config["mics"]["mic_type"] != "single":
                # If using arrays, compute angles to each device
                config = _compute_angles(config)
            
        config.update({
            "signal_duration_in_seconds": base_config["signal_duration_in_seconds"],
            "mask_delay": base_config["mask_delay"],
            "anechoic": base_config["anechoic"],
            "snr_in_db": base_config["mics"]["snr_in_db"],
            "signals_dir": output_dir,
            "sr": base_config["base_sampling_rate"],
            "ism_order": base_config["ism_order"],
            "acoustic_simulator": base_config["acoustic_simulator"],
            "mic_type": base_config["mics"]["mic_type"]
        })

    # 2. Simulate microphone recordings using the config

    if config["acoustic_simulator"] == "pyroomacoustics":
        signals = pyroomacoustics_simulator(config)
    elif config["acoustic_simulator"] == "gpuRIR":
        signals = gpu_rir_simulator(config)[0]
    
    # 3. Save signals on a provided output_dir
    if output_dir is not None:
        if "dataset_dir" in base_config and base_config["dataset_dir"] is not None:
            # If "dataset_dir" key is provided, save insided a dataset folder
            output_dir = Path(base_config["dataset_dir"]) / output_dir       

        os.makedirs(output_dir, exist_ok=True)
        save_signals(signals,
                     config["sr"],
                     output_dir)
        
        # Do not return input signals
        if "interferer_signals" in config:
            del config["interferer_signals"]
        
        if "vad" in config:
            del config["vad"]

        del config["source_signals"]

        return config
    
    return signals, config



def _initialize_directory(output_samples_dir):
    if os.path.exists(output_samples_dir):
        print(f"Warning: Dataset already exists at {output_samples_dir}.")

    os.makedirs(output_samples_dir, exist_ok=True)

    return output_samples_dir


def _create_speech_config(dataset_config):
    if dataset_config["acoustic_simulator"] == "gpuRIR":
        print("Loading Librispeech dataset, which is currently the only supported when using gpuRIR")
        dataset_config["librispeech_dataset"] = LibriSpeechDataset(
            dataset_config["sources"]["speech_signals_dir"],
            dataset_config["signal_duration_in_seconds"],
            return_vad=True)
    else:
        path = Path(dataset_config["sources"]["speech_signals_dir"])
        dataset_config["sources"]["speech_samples"] = [
            str(p) for p in path.rglob("*.wav")
        ]


def _compute_angle_between_vectors(v1, v2, radians=True):
    dot = np.dot(v1, v2)
    det = np.linalg.det([v1, v2])

    doa = np.arctan2(det, dot)

    if not radians:
        doa = np.rad2deg(doa)
    
    return doa


def _compute_angles(config):
    config["azimuths"] = []
    for mic_coords in config["mic_array_centres"]:
        angles = []
        for source_coords in config["source_coordinates"]:
            # Compute the angle the vector joining the source coordinates 
            # and mic centres makes with the x axis 
            d = np.array(source_coords)[:2] - np.array(mic_coords)[:2]
            angle = _compute_angle_between_vectors(d, np.array([1, 0]))
            angles.append(angle)
        config["azimuths"].append(angles)
    return config
